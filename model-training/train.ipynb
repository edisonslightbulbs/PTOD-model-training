{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MODEL TRAINING  USING THE TF OBJECT DETECTION API\n",
    "\n",
    "This notebook is based on modular [shell scripts](./scripts) for convenience. The scripts comprise minimal lines of code (LOC), on average, no more than 10 LOC for each, making them easy to read, learn, and adapt for future applications.\n",
    "\n",
    "**!!!Caveat :** \n",
    "\n",
    "Some scripts can be conveniently executed directly from this notebook, and some need to be executed in terminal to grant permissions. I recommend running each script from the terminal to see STDOUT clearly. If run in terminal, use the [module-training](./) directory as the working directory.\n",
    "\n",
    "***This is an academic project. Interested developers are invited to freely contribute issues, questions, improvements, and discussions.***\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QUANWN3rpfC9"
   },
   "source": [
    "## 1. CHECK SUBMODULES\n",
    "\n",
    "[`check-submodules.sh`](./scripts/) makes sure that the [LabelImg](https://github.com/tzutalin/labelImg) and [TF models](https://github.com/tensorflow/models) submodule repositories are initialized correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- checking submodules\r\n"
     ]
    }
   ],
   "source": [
    "!./scripts/check-submodules.sh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. CREATE VIRTUAL ENVIRONMENT\n",
    "\n",
    "[`venv.sh`](./scripts/) creates a virtual environment and installs essential [apt](./resources/apt.txt) and [pip](./resources/pip.txt) dependencies  [( see dependencies.sh )](./scripts/).Depending on your system, you may still need to install more dependencies in addition to yolov5's and labelImg's dependencies! The script should be executed from the terminal. This is necessary to grant install permissions. The default name of the virtual environment is **venv**. This name can, of course, be changed by simply passing a single argument representative of the name you want. From the working directory run \n",
    "\n",
    "`./scripts/venv.sh` # virtual environment name = venv\n",
    "\n",
    "or \n",
    "\n",
    "`./scripts/venv.sh my-venv-name` # virtual environment name = my-venv-name\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. TEST SETUP USING [EXAMPLE IN YOLOv5 DOCS](https://github.com/ultralytics/yolov5/wiki/Train-Custom-Data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import uuid  \n",
    "import os\n",
    "import cv2\n",
    "import time\n",
    "import torch\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline \n",
    "\n",
    "# test with *s model (https://github.com/ultralytics/yolov5#pretrained-checkpoints)\n",
    "model = torch.hub.load('ultralytics/yolov5', 'yolov5s', force_reload=True); \n",
    "img = 'https://ultralytics.com/images/zidane.jpg'\n",
    "results = model(img)\n",
    "results.print()\n",
    "\n",
    "\n",
    "plt.imshow(np.squeeze(results.render()))\n",
    "plt.show()\n",
    "#results.render()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Create [dataset.yaml spec](https://github.com/ultralytics/yolov5/wiki/Train-Custom-Data#1-create-datasetyaml) in the root directory of [Yolov5s' submodule directory](./external/yolov5) \n",
    "\n",
    "For this project, dataset.yaml looks like this\n",
    "\n",
    "```\n",
    "path: ../../resources/images\n",
    "train: train\n",
    "val: train\n",
    "\n",
    "nc: 1  # number of classes\n",
    "names: [ 'mobile device' ] # class  names\n",
    "\n",
    "```\n",
    "\n",
    "**!!!Caveat :** \n",
    "\n",
    "Also ensure to honor the location of the `labels` directory. It **must** exist in the same directory as the `images` directory (or whatever the directory's name where your training images are. The `labels` directory structure **must** also mirror the directory structure of the `images directory`!\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. TRAIN CUSTOM MODEL [Yolov5x model] (https://github.com/ultralytics/yolov5#pretrained-checkpoints)\n",
    "\n",
    "Training speces for this project are as follows\n",
    "\n",
    "* image size—320\n",
    "* image batch—16\n",
    "* image epochs—500\n",
    "* image weights—yolov5x\n",
    "* image workers—2\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!cd external/yolov5 && python3 train.py --img 320 --batch 16 --epochs 500 --data dataset.yaml --weights yolov5x.pt --workers 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. TEST TRAINED MODEL\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_model = torch.hub.load('ultralytics/yolov5', 'custom', path='external/yolov5/runs/train/exp7/weights/best.pt', force_reload=True)\n",
    "\n",
    "img = 'resources/images/test/20_scene.png'\n",
    "results = custom_model(img)\n",
    "results.print()\n",
    "\n",
    "plt.imshow(np.squeeze(results.render()))\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "3. Training and Detection.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
